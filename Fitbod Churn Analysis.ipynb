{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Business Problem and My Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitbod is a fitness app that creates a daily and deeply personalized workout routine by analyzing tracked workout data. It has been popular among people who love working out. However, Fitbod also faces customer attrition problem. Thus, it is important to predict which customer is going to churn out and take marketing strategies such as sending emails that promote the product or offering incentives to prevent them from churning out. In the following analyses, based on customers' activity records, I will build a prediction model that predicts which customers will be churning out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I first looked at the average interval of two subsequent workouts of each customer. I discovered that 87% of them have an interval of less than two weeks. Based on this finding, I define customers who haven't had any workout for more than 14 days as churned customers; \n",
    "\n",
    "2. I then looked at the usage of the 14-day period for churned and active customers; I found that the average number of exercises done by active customers is about 19.3, almost two times that of churned customers. Clearly the two groups of customers differ from each other a lot in terms of usage and thus usage within the 14-day period can be used as predictors of churn; \n",
    "\n",
    "3. Also, I suspected that active and churned customers have different preferences for muscle groups. I looked at the number of exercises done for each muscle groups by active and churned customers. The average numbers of back and quadricep exercises done by active customers are much more than that of churned customers, which indicates that the number of exercises done to improve different muscle groups are also informative of determining churn.\n",
    "\n",
    "4. Based on the discoveries from the above exploratory analysis, I use the number of exercises done on each day in the previous 14 days as well as the total number of exercises done for each muscle group to predict whether a customer will churn out on the eleventh day. After tuning parameters and comparing performances of algorithms, I chose decision tree to build the model. The model can identify 93% of the actual churned customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import graphviz\n",
    "# \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, \\\n",
    "                            precision_score, recall_score, f1_score, accuracy_score, \\\n",
    "                            roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in and Inspecting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fitbod_OuWenzhe_20200807-195605.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25267, 9)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>workoutId</th>\n",
       "      <th>exerciseId</th>\n",
       "      <th>singleSetId</th>\n",
       "      <th>exerciseName</th>\n",
       "      <th>reps</th>\n",
       "      <th>weight</th>\n",
       "      <th>fake_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>L9WbPdYFrx</td>\n",
       "      <td>h85ZOw37Wc</td>\n",
       "      <td>YVZTbtgZNL</td>\n",
       "      <td>Dumbbell Bench Press</td>\n",
       "      <td>5</td>\n",
       "      <td>24.947610</td>\n",
       "      <td>fake_id_361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>wib0nC1A5I</td>\n",
       "      <td>G1mxtZtEs5</td>\n",
       "      <td>y1nAkrqupp</td>\n",
       "      <td>Back Squat</td>\n",
       "      <td>5</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>fake_id_358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>u9LKojOiBd</td>\n",
       "      <td>h85ZOw37Wc</td>\n",
       "      <td>KmN8uwpHPB</td>\n",
       "      <td>Dumbbell Bench Press</td>\n",
       "      <td>12</td>\n",
       "      <td>22.679645</td>\n",
       "      <td>fake_id_417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>XWcgCyJBBj</td>\n",
       "      <td>mvkMgAdecH</td>\n",
       "      <td>OBPOCsPvc3</td>\n",
       "      <td>Dumbbell Shoulder Press</td>\n",
       "      <td>10</td>\n",
       "      <td>18.143716</td>\n",
       "      <td>fake_id_404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>rAxB3SPhhB</td>\n",
       "      <td>52vo7F7CLd</td>\n",
       "      <td>F3nOvbxhDD</td>\n",
       "      <td>Close-Grip Bench Press</td>\n",
       "      <td>7</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>fake_id_358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   workoutId  exerciseId singleSetId             exerciseName  \\\n",
       "0  2018-09-19  L9WbPdYFrx  h85ZOw37Wc  YVZTbtgZNL     Dumbbell Bench Press   \n",
       "1  2020-01-09  wib0nC1A5I  G1mxtZtEs5  y1nAkrqupp               Back Squat   \n",
       "2  2019-07-12  u9LKojOiBd  h85ZOw37Wc  KmN8uwpHPB     Dumbbell Bench Press   \n",
       "3  2019-11-21  XWcgCyJBBj  mvkMgAdecH  OBPOCsPvc3  Dumbbell Shoulder Press   \n",
       "4  2020-02-08  rAxB3SPhhB  52vo7F7CLd  F3nOvbxhDD   Close-Grip Bench Press   \n",
       "\n",
       "   reps     weight fake_user_id  \n",
       "0     5  24.947610  fake_id_361  \n",
       "1     5  80.000000  fake_id_358  \n",
       "2    12  22.679645  fake_id_417  \n",
       "3    10  18.143716  fake_id_404  \n",
       "4     7  55.000000  fake_id_358  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset that has information about each workout of customers, including the date, the type of exercises, reps, weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by=['fake_user_id','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverting Date variable to datetime type\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Back Squat', 'Barbell Bench Press', 'Deadlift',\n",
       "       'Dumbbell Shoulder Press', 'Close-Grip Bench Press',\n",
       "       'Dumbbell Bent Over Row', 'Dumbbell Lunge', 'Dumbbell Row',\n",
       "       'Dumbbell Bench Press'], dtype=object)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['exerciseName'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9 types of exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['fake_user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 101 customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date            0.0\n",
       "workoutId       0.0\n",
       "exerciseId      0.0\n",
       "singleSetId     0.0\n",
       "exerciseName    0.0\n",
       "reps            0.0\n",
       "weight          0.0\n",
       "fake_user_id    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null value in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding customers who had fewer than 3 workouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis, I only considered customers who had more than three workouts; Those customers are those who have converted and within the range of churning-out analysis; As for customers who had fewer than 3 workouts, they are probably new customers. They should be considered when we are doing landing analysis;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding customers who have only one record\n",
    "d1 = pd.DataFrame(data.groupby('fake_user_id')['workoutId'].nunique()).reset_index()\n",
    "irrelevant_ids = d1[d1['workoutId']<=3]['fake_user_id']\n",
    "data=data[data['fake_user_id'].isin(irrelevant_ids)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['fake_user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 96 customers left in the dataset;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing exercises, people always have a target muscle groups, so besides just having the exercises names, I'd like to see which muscle group the customers are actually working on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\n",
    "    'Dumbbell Bench Press':'Chest', 'Back Squat':'Quadricep', 'Dumbbell Shoulder Press':'Shoulders',\n",
    "       'Close-Grip Bench Press':'Tricep', 'Barbell Bench Press':'Chest', 'Deadlift':'Quadricep',\n",
    "       'Dumbbell Lunge':'Quadricep', 'Dumbbell Bent Over Row':'Back', 'Dumbbell Row':'Back'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Muscles'] = data['exerciseName'].map(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the analysis will not be using weight and reps variables, I didn't inspect these variables; But if I am doing an analysis where I will be using these variables, I will use boxplots to look at their distributions and remove outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval between activities of customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis, I will be looking at the average time interval between two workouts of a customer. The motivation for doing this analysis is: to see when is the appropriate time for Fitbod to take actions; If I discover that the majority of customers have a time interval shorter than X days, then if a customer is not using the app for a period longer than X days, it is very likely that the customers will not be using the app anymore and churn out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the time interval between workouts for each customer\n",
    "data2 = data.groupby('fake_user_id')['Date'].apply(lambda x:(x-x.shift(1)))\n",
    "data2 = pd.DataFrame(data2)\n",
    "data2['fake_user_id'] = data['fake_user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding irrelevant data points\n",
    "data2 = data2[(data2['Date']!='0 days')&(data2['Date'].isnull()==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the number of days between workouts\n",
    "data2['Date'] = data2['Date'].astype('str').str.split(n=1,expand=True)[0].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculating the average time interval for each customer and see the percentage of different time intervals\n",
    "eda1 = data2.groupby('fake_user_id')['Date'].mean().astype('int64').value_counts().sort_index()/ data['fake_user_id'].nunique()\n",
    "eda1 = pd.DataFrame(eda1.reset_index())\n",
    "eda1['Date'] = eda1['Date'] * 100\n",
    "eda1 = eda1.rename(columns={'index':'Day','Date':'Percentage'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda1.to_csv('fitbod_eda1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.5"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nearly 87.5% of customers have an average interval of fewer than 14 days\n",
    "eda1[eda1['Day']<=14]['Percentage'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 87.5% of customers have an average gap of equal to or fewer than 14 days. Based on this finding, we can say that if a customer hasn't have any workout for a more than 14 days interval, it is very likely he will never come back and has churned out; Thus, I define a customer who doesn't have any activity for more than 14 days as churned customers; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage of churned customers and active customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer activity usage is often a big indicator of churning. And the above analysis shows that a time period of 14 days is important in determing whether a customer will churn or not. In the following analysis, I will look at the workout usage of churned and active customers in a 14-day period. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do that, I need to do data engineering first..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding out churned customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today is 2020/8/7. I'll define customers whose latest activity record is before 2020/7/24 to be churned customers and customers whose whose latest activity record is after 2020/7/24 to be active customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not churn vs Churn: 1:3.5\n",
    "data_grouped_1 = data.groupby('fake_user_id')['Date'].max()>='2020-07-24'\n",
    "active_user_ids = data_grouped_1[data_grouped_1==True].index\n",
    "churned_user_ids = data_grouped_1[data_grouped_1==False].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_active = len(active_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_churned = len(churned_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_churned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 21 active customers and 75 churned customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the records of 14 days before the latest activity record for each customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped = pd.DataFrame(data.groupby('fake_user_id')['Date'].max().reset_index())\n",
    "data_grouped = data_grouped.rename(columns={'Date':'Max_Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake_user_id</th>\n",
       "      <th>Max_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>2020-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake_id_352</td>\n",
       "      <td>2020-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake_id_353</td>\n",
       "      <td>2019-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake_id_354</td>\n",
       "      <td>2020-06-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake_id_355</td>\n",
       "      <td>2020-01-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fake_user_id   Max_Date\n",
       "0  fake_id_351 2020-08-07\n",
       "1  fake_id_352 2020-07-15\n",
       "2  fake_id_353 2019-12-29\n",
       "3  fake_id_354 2020-06-22\n",
       "4  fake_id_355 2020-01-13"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting work out frequency of each muscle group for each customer\n",
    "exercises = pd.DataFrame(data.groupby(['fake_user_id','Date','Muscles']).size().reset_index())\n",
    "exercises = exercises.rename(columns={0:'times'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises = exercises.merge(data_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises['Max_Date'] = pd.to_datetime(exercises['Max_Date'])\n",
    "exercises['Date'] = pd.to_datetime(exercises['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake_user_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Muscles</th>\n",
       "      <th>times</th>\n",
       "      <th>Max_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>Quadricep</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>Quadricep</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>2020-07-29</td>\n",
       "      <td>Chest</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>Quadricep</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>Quadricep</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-08-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fake_user_id       Date    Muscles  times   Max_Date\n",
       "235  fake_id_351 2020-07-24  Quadricep      3 2020-08-07\n",
       "236  fake_id_351 2020-07-28  Quadricep     10 2020-08-07\n",
       "237  fake_id_351 2020-07-29      Chest      4 2020-08-07\n",
       "238  fake_id_351 2020-07-30  Quadricep      3 2020-08-07\n",
       "239  fake_id_351 2020-08-01  Quadricep      4 2020-08-07"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the last 14 days' activities\n",
    "exercises = exercises[(exercises['Max_Date'] - exercises['Date']).dt.days<=14]\n",
    "exercises.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining active status of each customer\n",
    "exercises['Churn'] = np.where(exercises['fake_user_id'].isin(fake_user_ids),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises['Day'] = 14 - (exercises['Max_Date'] - exercises['Date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for imputing records\n",
    "group = exercises.groupby('fake_user_id')['Date'].nunique()\n",
    "ids_14 = group[group==1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_14_churn = churned_user_ids[churned_user_ids.isin(ids_14)]\n",
    "ids_14_active = active_user_ids[active_user_ids.isin(ids_14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the total usage of churned customers\n",
    "churned_usage = pd.DataFrame(exercises[(exercises['Churn']==1)&(exercises['Day']<14)].groupby('fake_user_id')['times'].sum().value_counts().sort_index()).reset_index()\n",
    "df2 = pd.DataFrame([[0,len(ids_14_churn)]], columns=['index','times'])\n",
    "churned_usage = pd.concat([churned_usage,df2])\n",
    "churned_usage = churned_usage.rename(columns={'index':'exercises'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting the average number of exercises churned customers have done in the previous 14 days\n",
    "avg_churned = (churned_usage['times'] * churned_usage['exercises']).sum() / n_churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the total usage of active customers\n",
    "active_usage = pd.DataFrame(exercises[(exercises['Churn']==0)&(exercises['Day']<14)].groupby('fake_user_id')['times'].sum().value_counts().sort_index()).reset_index()\n",
    "df2 = pd.DataFrame([[0,len(ids_14_active)]], columns=['index','times'])\n",
    "active_usage = pd.concat([active_usage,df2])\n",
    "active_usage = active_usage.rename(columns={'index':'exercises'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting the average number of exercises active customers have done in the previous 14 days\n",
    "avg_active = (active_usage['times'] * active_usage['exercises']).sum() / n_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_usage_df = pd.DataFrame({'Customer Type':['Active','Churned'],\n",
    "                             'Average Usage':[avg_active,avg_churned]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Average Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Active</td>\n",
       "      <td>19.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Churned</td>\n",
       "      <td>9.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer Type  Average Usage\n",
       "0        Active      19.333333\n",
       "1       Churned       9.866667"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_usage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1fe0ceb8>"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_usage_df.plot.barh(x='Customer Type',y='Average Usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Besides plotting them out, I want to do a statistical t-test to see if they are statistically different from each other\n",
    "churned_df = pd.DataFrame(exercises[(exercises['Churn']==1)&(exercises['Day']<14)].groupby('fake_user_id')['times'].sum()).reset_index()\n",
    "churned_df2 = pd.DataFrame({'fake_user_id':ids_14_churn,'times':0})\n",
    "churned_df = pd.concat([churned_df,churned_df2])\n",
    "\n",
    "active_df = pd.DataFrame(exercises[(exercises['Churn']==0)&(exercises['Day']<14)].groupby('fake_user_id')['times'].sum()).reset_index()\n",
    "active_df2 = pd.DataFrame({'fake_user_id':ids_14_active,'times':0})\n",
    "active_df = pd.concat([active_df,active_df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.8287336774119933, pvalue=0.009538194840459795)"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(churned_df['times'], active_df['times'], equal_var = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is very small. The numbers of exercises done by these two groups are statistically significant different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the average number of exercises an active customer has done in the previous 14 days is 19.3 while that of a churned customer is 9.8; The average number of exercises of an active customer is almost twice as many as that of a churned customer; Also, the t-test shows these two groups are statistically significant different in terms of their workout frequency. We can see that active customers differ from churned customers in usage a lot. And thus the activity usage in the previous 14 days is indicative of churn;\n",
    "\n",
    "There is also another practical reason for using the previous 14 days information. Updating the model and taking actions towards churned customers bi-weekly is more timely and accurate than monthly and less costly than daily. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of muscle groups active customers and churned customers have been working on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following analysis, I will be looking at the average number of exercises active and churned customers have done to work on different muscle groups; The intuition of looking at this feature is Fitbod offering recommendation on reps, sets and weight. It is likely that for people who are working on certain muscle groups, recommendations is much more effective than working alone and thus this type of people will have have less chance of churning out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoting table\n",
    "exercises_1 = exercises.pivot_table(index=['fake_user_id', 'Day'], columns='Muscles', values='times', fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing missing days among active days when there is no usage information\n",
    "exercises_1['next_day'] = exercises_1.groupby('fake_user_id')['Day'].apply(lambda x:x.shift(-1))\n",
    "exercises_1['next_day'] = exercises_1['next_day'].fillna(0)\n",
    "exercises_1['next_day'] = exercises_1['next_day'].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "muscles_n = data['Muscles'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "muscles = data['Muscles'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = exercises_1[(exercises_1['next_day'] - exercises_1['Day'] > 1)&(exercises_1['next_day']!=0)]['fake_user_id'].values\n",
    "f = exercises_1[(exercises_1['next_day'] - exercises_1['Day'] > 1)&(exercises_1['next_day']!=0)]['Day'].values\n",
    "t = exercises_1[(exercises_1['next_day'] - exercises_1['Day'] > 1)&(exercises_1['next_day']!=0)]['next_day'].values\n",
    "left_df = pd.DataFrame(dict(\n",
    "        fake_user_id=r.repeat(muscles_n*(t - f - 1)),\n",
    "        Day=np.concatenate([np.repeat(np.arange(f+1, t),muscles_n) for f, t in zip(f, t)]),\n",
    "        Muscles=np.concatenate([list(muscles)*(t-f-1) for f, t in zip(f, t)]),\n",
    "        times=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake_user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>Back</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Quadricep</th>\n",
       "      <th>Shoulders</th>\n",
       "      <th>Tricep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fake_user_id  Day  Back  Chest  Quadricep  Shoulders  Tricep\n",
       "0  fake_id_351    1     0      0          0          0       0\n",
       "1  fake_id_351    2     0      0          0          0       0\n",
       "2  fake_id_351    3     0      0          0          0       0\n",
       "3  fake_id_351    7     0      0          0          0       0\n",
       "4  fake_id_351    9     0      0          0          0       0"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_df = left_df.pivot_table(index=['fake_user_id', 'Day'], columns='Muscles', values='times', fill_value=0).reset_index()\n",
    "left_df = left_df.rename_axis(None, axis=\"columns\")\n",
    "left_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_records = pd.DataFrame(exercises_1.groupby('fake_user_id').size()==1).reset_index()\n",
    "one_records_ids = one_records[one_records[0]==True]['fake_user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing records of customers who didn't work out for the 14 days before their latest active day\n",
    "imputed_df = pd.DataFrame(dict(fake_user_id=np.repeat(list(one_records_ids),14),\n",
    "                               Day=list(range(14))*len(one_records_ids),\n",
    "                               Back=list([0])*14*len(one_records_ids),\n",
    "                               Chest=list([0])*14*len(one_records_ids),\n",
    "                               Quadricep=list([0])*14*len(one_records_ids),\n",
    "                               Shoulders=list([0])*14*len(one_records_ids),\n",
    "                               Tricep=list([0])*14*len(one_records_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake_user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>Back</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Quadricep</th>\n",
       "      <th>Shoulders</th>\n",
       "      <th>Tricep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake_id_354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake_id_354</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake_id_354</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake_id_354</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake_id_354</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fake_user_id  Day  Back  Chest  Quadricep  Shoulders  Tricep\n",
       "0  fake_id_354    0     0      0          0          0       0\n",
       "1  fake_id_354    1     0      0          0          0       0\n",
       "2  fake_id_354    2     0      0          0          0       0\n",
       "3  fake_id_354    3     0      0          0          0       0\n",
       "4  fake_id_354    4     0      0          0          0       0"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises_1 = exercises_1.drop('next_day',axis=1)\n",
    "df = pd.concat([left_df,exercises_1,imputed_df])\n",
    "df = df.sort_values(by=['fake_user_id','Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the sum of exercises of each muscle group\n",
    "df1 = df[df['Day']!=14].groupby('fake_user_id').sum()[['Back', 'Chest', 'Quadricep', 'Shoulders', 'Tricep']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.set_index(['fake_user_id','Day']).sum(axis=1).reset_index().rename(columns={0:'times'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake_user_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>Back</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Quadricep</th>\n",
       "      <th>Shoulders</th>\n",
       "      <th>Tricep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake_id_352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake_id_353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake_id_354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake_id_355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fake_user_id  0  1  2  3   4  5  6  7  8  9  10  11  12  13  Back  Chest  \\\n",
       "0  fake_id_351  3  0  0  0  10  4  3  0  4  0   0  11   6   0     0     10   \n",
       "1  fake_id_352  0  0  8  0   0  4  0  0  0  0   0   0   0   0     4      0   \n",
       "2  fake_id_353  0  0  0  0   0  0  0  0  0  0   0   0   4   0     0      0   \n",
       "3  fake_id_354  0  0  0  0   0  0  0  0  0  0   0   0   0   0     0      0   \n",
       "4  fake_id_355  0  0  0  0   0  0  0  8  0  0   4   0   0   0     4      4   \n",
       "\n",
       "   Quadricep  Shoulders  Tricep  \n",
       "0         31          0       0  \n",
       "1          8          0       0  \n",
       "2          4          0       0  \n",
       "3          0          0       0  \n",
       "4          4          0       0  "
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2[df2['Day']!=14].pivot_table(index=['fake_user_id'], columns='Day', values='times', fill_value=0).reset_index()\n",
    "df2 = df2.merge(df1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['churn'] = np.where(df2['fake_user_id'].isin(fake_user_ids),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Back</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Quadricep</th>\n",
       "      <th>Shoulders</th>\n",
       "      <th>Tricep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.450000</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.447368</td>\n",
       "      <td>2.960526</td>\n",
       "      <td>3.026316</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Back     Chest  Quadricep  Shoulders    Tricep\n",
       "churn                                                    \n",
       "0      5.450000  4.450000   7.300000   2.450000  0.650000\n",
       "1      1.447368  2.960526   3.026316   1.421053  0.881579"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('churn').mean()[['Back', 'Chest', 'Quadricep', 'Shoulders', 'Tricep']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the average number of back exercises active customers has done is about 4 times that of churned customers; For quadricep, the average number of exercises active customers has done is more than 2 times that of churned customers; But for chest, shoulders, the difference is not that large and for tricep, it shows that the average number of exercises done by churned customers is even higher than that of the active customers; Remember, the above analysis has shown that the average number of exercises active customers has done is twice that of churned customers. Based on the results of these two analyses, we can see that the active customers tend to do more quadricep and back exercises; Clearly, the types of muscle groups customers have been working on is informative in determining which customer is going to churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake_user_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>Back</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Quadricep</th>\n",
       "      <th>Shoulders</th>\n",
       "      <th>Tricep</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake_id_351</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake_id_352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake_id_353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake_id_354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake_id_355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fake_user_id  0  1  2  3   4  5  6  7  8  ...  10  11  12  13  Back  Chest  \\\n",
       "0  fake_id_351  3  0  0  0  10  4  3  0  4  ...   0  11   6   0     0     10   \n",
       "1  fake_id_352  0  0  8  0   0  4  0  0  0  ...   0   0   0   0     4      0   \n",
       "2  fake_id_353  0  0  0  0   0  0  0  0  0  ...   0   0   4   0     0      0   \n",
       "3  fake_id_354  0  0  0  0   0  0  0  0  0  ...   0   0   0   0     0      0   \n",
       "4  fake_id_355  0  0  0  0   0  0  0  8  0  ...   4   0   0   0     4      4   \n",
       "\n",
       "   Quadricep  Shoulders  Tricep  churn  \n",
       "0         31          0       0      0  \n",
       "1          8          0       0      1  \n",
       "2          4          0       0      1  \n",
       "3          0          0       0      1  \n",
       "4          4          0       0      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 0-13 columns indicate the total exercises of every day in the previous 14 day period for each customer while the muscle group columns show the total exercises done for different muscle groups; And the churn column indicate the status of each customer; The dataset is ready for model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Prediction Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df2['churn']\n",
    "X=df2.drop(['churn','fake_user_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.4,random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following analysis, I will try to build the model based on five commonly seen machine learning algorithms(K nearest neighbour, Logistic Regression, Decision Tree, Support Vector Machine and Random Forest). They can be used in this model building as they are supervised machine learning and predict the labels of test objects.\n",
    "\n",
    "I will also show the performance of four metrics of models (accuracy, precision, recall, f1); Accuracy measures how correct the models' predictions are; Precision measures out of all predicted churned customers, how many are correctly predicted while recall measures the percentage of actual churned customers the model has successfully identified; As there is tradeoff between precision and recall(one of them could become 0 and makes the other one very high, f1 which is the harmonic mean of the recall and precision is also used in this analysis to show the performance of five models;\n",
    "\n",
    "Out of four metrics I have used, I mainly use recall as the metric to gauge the performace of classifiers; In a churn problem, it is more important for the model to find out churned customers as many as possible, thus I chose recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['KNN','Logistic_regression','Decision_tree','SVC','Random Forest']\n",
    "classifiers = [KNeighborsClassifier(algorithm='auto'),\n",
    "               linear_model.LogisticRegression(random_state=42),\n",
    "               DecisionTreeClassifier(),\n",
    "               SVC(),\n",
    "               RandomForestClassifier()]\n",
    "parameters = {'KNN':{\"n_neighbors\": range(5,20),\n",
    "                     \"weights\": ['uniform','distance']},\n",
    "              'Logistic_regression': {\"C\": np.arange(0.5,2.0,0.1)},\n",
    "              'Decision_tree':{\"max_depth\": range(3,15),\n",
    "                               \"criterion\" : ['gini', 'entropy']},\n",
    "              'SVC':{'C': np.arange(0.5,10,0.1),\n",
    "                     'kernel':['rbf', 'linear']},\n",
    "              'Random Forest':{\"max_depth\": range(3,15),\n",
    "                               \"criterion\" : ['gini', 'entropy']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name: KNN\n",
      "best_params: {'n_neighbors': 9, 'weights': 'uniform'}\n",
      "[[ 0  8]\n",
      " [ 1 30]]\n",
      "{'accuracy': 0.7692307692307693, 'precision': 0.7894736842105263, 'recall': 0.967741935483871, 'f1': 0.7692307692307693}\n",
      "\n",
      "name: Logistic_regression\n",
      "best_params: {'C': 0.5}\n",
      "[[ 1  7]\n",
      " [ 2 29]]\n",
      "{'accuracy': 0.7692307692307693, 'precision': 0.8055555555555556, 'recall': 0.9354838709677419, 'f1': 0.7692307692307693}\n",
      "\n",
      "name: Decision_tree\n",
      "best_params: {'criterion': 'gini', 'max_depth': 11}\n",
      "[[ 4  4]\n",
      " [ 3 28]]\n",
      "{'accuracy': 0.8205128205128205, 'precision': 0.875, 'recall': 0.9032258064516129, 'f1': 0.8205128205128205}\n",
      "\n",
      "name: SVC\n",
      "best_params: {'C': 0.5, 'kernel': 'rbf'}\n",
      "[[ 0  8]\n",
      " [ 0 31]]\n",
      "{'accuracy': 0.7948717948717948, 'precision': 0.7948717948717948, 'recall': 1.0, 'f1': 0.7948717948717948}\n",
      "\n",
      "name: Random Forest\n",
      "best_params: {'criterion': 'gini', 'max_depth': 3}\n",
      "[[ 2  6]\n",
      " [ 1 30]]\n",
      "{'accuracy': 0.8205128205128205, 'precision': 0.8333333333333334, 'recall': 0.967741935483871, 'f1': 0.8205128205128205}\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "for name, clf in zip(names, classifiers):\n",
    "    grid_clf = GridSearchCV(clf, parameters[name],cv = 10, scoring='recall')\n",
    "    grid_clf.fit(X_train, y_train)\n",
    "    print ('\\nname:', name)\n",
    "    print ('best_params:', grid_clf.best_params_)\n",
    "    \n",
    "    # Look at the model with other evaluation metrics\n",
    "    pred = grid_clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred,average='binary')\n",
    "    recall = recall_score(y_test, pred,average='binary')\n",
    "    f1 = f1_score(y_test, pred,average='micro')\n",
    "    \n",
    "    eval_dict = {'accuracy': accuracy,\n",
    "                 'precision': precision,\n",
    "                 'recall': recall,\n",
    "                 'f1': f1}\n",
    "    print(confusion_matrix(y_test, pred))\n",
    "    print(eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randorm forest, support vector machines and K-nearest neighbour have good recall scores; However, at the closer look at them, K-nearest neightbour and Support Vector Machine nearly predicts all of the test objects to be churned; This is equal to take marketing strategies towards all customers and thus the model will not be needed; Thus, it is reasonable to use random forest.\n",
    "\n",
    "Intuitively, random forest is very suited for this problem. First, the previous exploratory analyses have shown that there is great distinction between churned and active customers in terms of the inputted features. Having great distinction can make decision trees which are the components of random forest split nodes easily; Secondly, random forest is an ensemble model made up of random trees. It has improved model performance and less bias than decision tree; One of the biggest cons of decision tree is it is unstable and has high variance. Small changes in the training dataset can lead to big change in the structure of the decision tree. But for random forest, each tree of random forest uses a different subset of features and training data. And it uses majority votes of trees when predicting. Variance can be reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [ 1 30]]\n",
      "{'accuracy': 0.8205128205128205, 'precision': 0.8333333333333334, 'recall': 0.967741935483871, 'f1': 0.8205128205128205}\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion='gini', max_depth=3)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred,average='binary')\n",
    "recall = recall_score(y_test, pred,average='binary')\n",
    "f1 = f1_score(y_test, pred,average='micro')\n",
    "eval_dict = {'accuracy': accuracy,\n",
    "                 'precision': precision,\n",
    "                 'recall': recall,\n",
    "                 'f1': f1}\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Quadricep</td>\n",
       "      <td>0.221839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.184786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Back</td>\n",
       "      <td>0.134815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.075321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.064661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.063413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.044763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chest</td>\n",
       "      <td>0.040310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.038426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.029429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.027127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.024262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.014162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.014054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.004777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tricep</td>\n",
       "      <td>0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Shoulders</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Importances\n",
       "16  Quadricep     0.221839\n",
       "13         13     0.184786\n",
       "14       Back     0.134815\n",
       "2           2     0.075321\n",
       "8           8     0.064661\n",
       "0           0     0.063413\n",
       "12         12     0.044763\n",
       "15      Chest     0.040310\n",
       "11         11     0.038426\n",
       "7           7     0.029429\n",
       "5           5     0.027127\n",
       "3           3     0.024262\n",
       "1           1     0.015846\n",
       "10         10     0.014162\n",
       "4           4     0.014054\n",
       "9           9     0.004777\n",
       "18     Tricep     0.002008\n",
       "6           6     0.000000\n",
       "17  Shoulders     0.000000"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.DataFrame({'Features':X.columns,\n",
    "                            'Importances':clf.feature_importances_})\n",
    "features_df.sort_values(by='Importances',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the number of quadricep exercises, the number of exercises done on day 14 and the number of back exercises are the most important features in determining which customers are going to churn out; The result is also in line with the above exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations & Next Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset is small, the model is not very robust in predicting churn. \n",
    "\n",
    "In the following section, I'll be talking about how I will be building models if I am given a larger dataset.\n",
    "\n",
    "About churn prediction:\n",
    "1. If there is more information provided, I will be looking at other information such as the profiles for churned and active groups to see if they are also informative in churn prediction; And if in that case, I have discovered many more features, I'll be doing feature selection or dimensionality reduction.\n",
    "2. And if in the real dataset, it is likely that the target label is hugely imbalanced. To cope with this problem, I'll take a subset from the data by randomly sampling from active and churned groups so that the ratio of active to churned customers be normal(e.g.one to four); Also, I'll be using AUC to gauge performance of models;\n",
    "\n",
    "What other analyses can be done with a larger dataset?\n",
    "1. Association rules analysis; As there are only 5 muscle groups in this small dataset, it doesn't make sense to do association rules analysis; But if the real dataset is provided, I can use association rules analysis to find out the most commonly appeared muscle groups exercises and provide recommendations to customers; For example, I discover that chest, shoulders, and triceps appear together often. Then I can recommend customers who have focused on chest and triceps to also work on shoulders;\n",
    "\n",
    "2. Clustering analysis; We can also perform clustering analysis on customers based on their usage; This can be used when we are trying to do marketing. We can develop personalized marketing strategies for different segments of customers; For example, for people who work out heavily, we can focus on building muscles; But for people who prefer light workouts, we can focus on staying healthy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis, I have used random forest model to predict customer churn based on the number of exercises done in the previous 14 days and different muscle groups. The model can identify 96% of actual churned customers. However, as the dataset is very small, it is likely that the model is not very robust. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
